{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:26<00:00, 6.50MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the AlexNet architecture\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):  # Default is 10 classes for CIFAR-10\n",
    "        super(AlexNet, self).__init__()\n",
    "        # Feature extraction layers (convolutional layers)\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv1: Input channels=3 (RGB), Output channels=96, Kernel size=11x11, Stride=4, Padding=0\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),  # Output: 55x55x96\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # Max pooling, Output: 27x27x96\n",
    "            # Conv2: Input channels=96, Output channels=256, Kernel size=5x5, Padding=2\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),  # Output: 27x27x256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # Max pooling, Output: 13x13x256\n",
    "            # Conv3: Input channels=256, Output channels=384, Kernel size=3x3, Padding=1\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),  # Output: 13x13x384\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Conv4: Input channels=384, Output channels=384, Kernel size=3x3, Padding=1\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),  # Output: 13x13x384\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Conv5: Input channels=384, Output channels=256, Kernel size=3x3, Padding=1\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),  # Output: 13x13x256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # Max pooling, Output: 6x6x256\n",
    "        )\n",
    "        # Adaptive average pooling to ensure output is 6x6x256\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        # Fully connected layers (classifier)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),  # Dropout for regularization\n",
    "            nn.Linear(256 * 6 * 6, 4096),  # Fully connected layer\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),  # Dropout for regularization\n",
    "            nn.Linear(4096, 4096),  # Fully connected layer\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),  # Output layer (10 classes for CIFAR-10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        x = self.features(x)  # Pass through convolutional layers\n",
    "        x = self.avgpool(x)  # Apply adaptive average pooling\n",
    "        x = torch.flatten(x, 1)  # Flatten the tensor for fully connected layers\n",
    "        x = self.classifier(x)  # Pass through fully connected layers\n",
    "        return x\n",
    "\n",
    "# Prepare the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  # Resize images to 227x227 for AlexNet\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training and test datasets\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "model = AlexNet(num_classes=10).to(device)  # Move model to GPU\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer (Adam)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10  # Number of training epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0  # Track loss for each epoch\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass (compute gradients)\n",
    "        optimizer.step()  # Update weights\n",
    "        running_loss += loss.item()  # Accumulate loss\n",
    "        if (i + 1) % 100 == 0:  # Print loss every 100 steps\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Test the model on the test set\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0  # Count correct predictions\n",
    "total = 0  # Total number of predictions\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
    "        total += labels.size(0)  # Update total count\n",
    "        correct += (predicted == labels).sum().item()  # Update correct count\n",
    "\n",
    "# Print accuracy on the test set\n",
    "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"alexnet_cifar10.pth\")\n",
    "\n",
    "# Test the model on 10 images and plot the results\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize the image\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Convert from Tensor to NumPy and plot\n",
    "    plt.show()\n",
    "\n",
    "# Get 10 random test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images[:10].to(device), labels[:10].to(device)\n",
    "\n",
    "# Make predictions\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Move images and labels back to CPU for plotting\n",
    "images = images.cpu()\n",
    "labels = labels.cpu()\n",
    "predicted = predicted.cpu()\n",
    "\n",
    "# Plot the images with their predicted and true labels\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    imshow(images[i])\n",
    "    plt.title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[predicted[i]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
